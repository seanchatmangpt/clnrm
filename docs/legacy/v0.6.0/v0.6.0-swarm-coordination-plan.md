# v0.6.0 Hierarchical Swarm Coordination Plan

## Executive Summary

**Mission**: Implement clnrm v0.6.0 Tera templating system using 12-agent hierarchical swarm with London TDD methodology.

**Current State Analysis** (2025-10-16):
- **Version**: 0.5.0 (stable, OTEL validation complete)
- **WIP State**: Template module partially implemented (mod.rs, context.rs, functions.rs, determinism.rs)
- **Tests**: 356 passing, 0 failing, 26 ignored
- **Architecture**: Complete v0.6.0 architecture documented in `docs/architecture/tera-v0.6.0-architecture.md`

**v0.6.0 Scope**:
1. Tera template rendering (BEFORE TOML parsing)
2. Custom Tera functions (env, now_rfc3339, sha256, toml_encode)
3. New validators (OrderValidator, StatusValidator)
4. Multi-format reporting (JSON, JUnit, Digest)
5. Determinism support (clock freezing, seeding)
6. Backward compatibility (non-template files work unchanged)

---

## Hierarchical Swarm Structure

```
                    ðŸ‘‘ HIVE QUEEN (Coordinator)
                   /         |         \
                  /          |          \
         ðŸ”¬ SC1: R&A    ðŸ’» SC2: I&T    ðŸ“Š SC3: Q&I
        (Research &     (Implementation  (Quality &
       Architecture)      & Testing)    Integration)
           /|\              /|\             /|\
          / | \            / | \           / | \
         /  |  \          /  |  \         /  |  \
        W1 W2 W3         W4 W5 W6        W7 W8 W9
```

### Sub-Coordinator 1: Research & Architecture (SC1)
**Responsibility**: Validate requirements and design system components

**Workers**:
- **W1: Architecture Analyst** - Verify Tera integration points match existing system
- **W2: Requirements Validator** - Red-team architecture against clnrm core standards
- **W3: API Designer** - Design public APIs for template module

### Sub-Coordinator 2: Implementation & Testing (SC2)
**Responsibility**: Implement features with London TDD (outside-in, mock-driven)

**Workers**:
- **W4: Template Engine Developer** - Complete template module implementation
- **W5: Validator Developer** - Implement OrderValidator and StatusValidator
- **W6: Reporting Developer** - Implement multi-format reporters

### Sub-Coordinator 3: Quality & Integration (SC3)
**Responsibility**: Ensure production quality and integration

**Workers**:
- **W7: Test Engineer** - Create comprehensive test suite (unit, integration, E2E)
- **W8: Integration Specialist** - Integrate all components into main pipeline
- **W9: Quality Auditor** - Validate against Definition of Done

---

## Coordination Protocol

### Phase 1: Strategic Planning (Hive Queen)
1. Analyze current WIP state âœ…
2. Validate architecture completeness âœ…
3. Create coordination plan âœ…
4. Initialize sub-coordinators

### Phase 2: Parallel Execution (Sub-Coordinators)

#### SC1: Research & Architecture
**Deliverables**:
- Architecture validation report
- API design specifications
- Integration point analysis

**Tasks**:
1. W1: Analyze existing module structure against v0.6.0 architecture
2. W2: Red-team design for unwrap/expect violations and false positives
3. W3: Design public APIs following clnrm standards

#### SC2: Implementation & Testing
**Deliverables**:
- Complete template module implementation
- OrderValidator and StatusValidator
- JSON/JUnit/Digest reporters

**Tasks**:
1. W4: Complete template rendering pipeline (AAA pattern tests)
2. W5: Implement new validators with comprehensive tests
3. W6: Implement multi-format reporting system

#### SC3: Quality & Integration
**Deliverables**:
- 80+ tests (unit, integration, E2E)
- Full pipeline integration
- Quality audit report

**Tasks**:
1. W7: Create comprehensive test suite
2. W8: Integrate template rendering into config loader
3. W9: Validate against Definition of Done

### Phase 3: Integration & Delivery (Hive Queen)
1. Collect all deliverables
2. Validate integration
3. Run full test suite
4. Generate release documentation
5. Create git commit

---

## London TDD Workflow

### Outside-In Development
1. **Start with acceptance test** (E2E test defining user-visible behavior)
2. **Mock dependencies** (use test doubles for collaborators)
3. **Drive implementation** (write just enough code to pass tests)
4. **Refactor** (improve design while keeping tests green)

### Example: Template Rendering

```rust
// Step 1: Acceptance test (outside)
#[test]
fn test_template_rendering_with_variables() {
    // Arrange
    let config = load_config_from_file("test.clnrm.toml")?;

    // Act
    let rendered = render_template(config)?;

    // Assert
    assert!(rendered.contains("expected_output"));
}

// Step 2: Mock dependencies (London TDD)
#[test]
fn test_template_renderer_calls_tera() {
    // Arrange
    let mock_tera = MockTera::new();
    let renderer = TemplateRenderer::with_tera(mock_tera);

    // Act
    renderer.render("{{ var }}", context)?;

    // Assert
    mock_tera.verify_called_with("{{ var }}", context);
}

// Step 3: Implement just enough (inside)
impl TemplateRenderer {
    pub fn render(&self, template: &str, context: &Context) -> Result<String> {
        self.tera.render_str(template, context)
            .map_err(|e| CleanroomError::template_error(e.to_string()))
    }
}
```

---

## Agent Assignments

### SC1: Research & Architecture

#### W1: Architecture Analyst
**Goal**: Validate v0.6.0 architecture against existing codebase

**Tasks**:
1. Compare `docs/architecture/tera-v0.6.0-architecture.md` with current implementation
2. Identify gaps between design and WIP state
3. Validate module structure matches architecture
4. Document integration points

**Deliverable**: `docs/v0.6.0-architecture-validation.md`

#### W2: Requirements Validator
**Goal**: Red-team architecture for violations of core standards

**Tasks**:
1. Scan for potential `.unwrap()` and `.expect()` violations
2. Verify all trait methods are sync (no async in traits)
3. Check for false positive risks
4. Validate error handling strategy

**Deliverable**: `docs/v0.6.0-red-team-analysis.md`

#### W3: API Designer
**Goal**: Design public APIs following clnrm conventions

**Tasks**:
1. Design `TemplateRenderer` public API
2. Design `Reporter` trait and implementations
3. Design `Validator` trait extensions
4. Create API documentation

**Deliverable**: `docs/api/v0.6.0-public-api.md`

---

### SC2: Implementation & Testing

#### W4: Template Engine Developer
**Goal**: Complete template module implementation

**Tasks**:
1. Finish `template/mod.rs` implementation
2. Complete custom Tera functions
3. Implement template detection and rendering pipeline
4. Add to `config/mod.rs` integration

**Deliverable**: Working template rendering system

**Test Requirements**:
- Unit tests for each Tera function
- Integration tests for rendering pipeline
- Error handling tests

#### W5: Validator Developer
**Goal**: Implement OrderValidator and StatusValidator

**Tasks**:
1. Create `validation/order_validator.rs`
2. Create `validation/status_validator.rs`
3. Register validators in `validation/mod.rs`
4. Add to validator chain

**Deliverable**: Two new validators with comprehensive tests

**Test Requirements**:
- Unit tests for ordering logic
- Unit tests for status matching
- Integration tests with real spans

#### W6: Reporting Developer
**Goal**: Implement multi-format reporting system

**Tasks**:
1. Create `reporting/` module
2. Implement `JsonReporter`
3. Implement `JUnitReporter`
4. Implement `DigestReporter`
5. Add CLI integration

**Deliverable**: Three reporters with output validation

**Test Requirements**:
- Unit tests for each reporter
- Output format validation
- File writing tests

---

### SC3: Quality & Integration

#### W7: Test Engineer
**Goal**: Create comprehensive test suite

**Tasks**:
1. Write unit tests (50+ tests)
2. Write integration tests (20+ tests)
3. Write E2E tests (10+ tests)
4. Add red-team tests (false positive detection)

**Deliverable**: 80+ tests covering all v0.6.0 features

**Coverage Targets**:
- Template rendering: 100%
- Custom functions: 100%
- Validators: 100%
- Reporters: 100%

#### W8: Integration Specialist
**Goal**: Integrate all components into main pipeline

**Tasks**:
1. Integrate template rendering into `config/mod.rs`
2. Wire up new validators in validator chain
3. Add reporting to execution pipeline
4. Update CLI commands

**Deliverable**: Fully integrated v0.6.0 pipeline

**Integration Points**:
- `config::load_config_from_file()` - Add template rendering
- `validation::create_validator_chain()` - Register new validators
- `cli::commands::run` - Add reporting options

#### W9: Quality Auditor
**Goal**: Validate against Definition of Done

**Tasks**:
1. Run `cargo build --release` (zero warnings)
2. Run `cargo test` (all passing)
3. Run `cargo clippy -- -D warnings` (zero issues)
4. Verify no `.unwrap()` or `.expect()` in production code
5. Validate error handling
6. Check for false positives

**Deliverable**: `docs/v0.6.0-quality-audit.md`

**Definition of Done Checklist**:
- [ ] `cargo build --release` succeeds with zero warnings
- [ ] `cargo test` passes completely
- [ ] `cargo clippy -- -D warnings` shows zero issues
- [ ] No `.unwrap()` or `.expect()` in production code paths
- [ ] All traits remain `dyn` compatible
- [ ] Proper `Result<T, CleanroomError>` error handling
- [ ] Tests follow AAA pattern with descriptive names
- [ ] No `println!` in production code
- [ ] No fake `Ok(())` returns from incomplete implementations
- [ ] Framework self-test validates the feature

---

## Deliverables Matrix

| Agent | Deliverable | Location | Type |
|-------|-------------|----------|------|
| W1 | Architecture Validation | `docs/v0.6.0-architecture-validation.md` | Documentation |
| W2 | Red-Team Analysis | `docs/v0.6.0-red-team-analysis.md` | Documentation |
| W3 | Public API Design | `docs/api/v0.6.0-public-api.md` | Documentation |
| W4 | Template Module | `crates/clnrm-core/src/template/` | Code |
| W5 | Validators | `crates/clnrm-core/src/validation/` | Code |
| W6 | Reporters | `crates/clnrm-core/src/reporting/` | Code |
| W7 | Test Suite | `crates/clnrm-core/tests/` | Tests |
| W8 | Integration | `crates/clnrm-core/src/` | Code |
| W9 | Quality Audit | `docs/v0.6.0-quality-audit.md` | Documentation |

---

## Success Metrics

### Code Quality
- **Zero warnings** on `cargo build --release`
- **Zero clippy violations** with `-D warnings`
- **356+ passing tests** (maintaining current baseline)
- **80+ new tests** for v0.6.0 features

### Functionality
- **Template rendering** works with Tera syntax
- **Custom functions** (env, now_rfc3339, sha256, toml_encode) work correctly
- **New validators** (OrderValidator, StatusValidator) catch violations
- **Reporters** generate valid JSON/JUnit/Digest output
- **Backward compatibility** - all v0.5.0 files work unchanged

### Documentation
- **Architecture validation** confirms design matches implementation
- **Red-team analysis** identifies and fixes potential issues
- **API documentation** provides clear usage examples
- **Quality audit** validates Definition of Done

---

## Timeline

### Week 1: Architecture & Foundation
- **Days 1-2**: SC1 completes architecture validation and API design
- **Days 3-5**: SC2 begins implementation with London TDD
- **Days 6-7**: SC3 starts integration planning

### Week 2: Implementation
- **Days 8-10**: SC2 completes core implementation
- **Days 11-12**: SC3 writes comprehensive test suite
- **Days 13-14**: SC3 integrates all components

### Week 3: Quality & Release
- **Days 15-17**: SC3 runs quality audits
- **Days 18-19**: Hive Queen integrates all deliverables
- **Days 20-21**: Final validation and release preparation

---

## Risk Mitigation

### Risk 1: Breaking Backward Compatibility
**Mitigation**: W7 creates comprehensive regression tests for v0.5.0 files

### Risk 2: False Positives in New Validators
**Mitigation**: W2 red-teams validator logic before implementation

### Risk 3: Performance Degradation
**Mitigation**: W7 includes performance benchmarks in test suite

### Risk 4: Template Security Issues
**Mitigation**: W2 analyzes template injection risks; W4 implements safeguards

### Risk 5: Integration Failures
**Mitigation**: W8 integrates incrementally with tests at each step

---

## Communication Protocol

### Daily Status Updates
Each sub-coordinator reports to Hive Queen:
- **Progress**: What was completed
- **Blockers**: What is preventing progress
- **Next Steps**: What will be done next

### Coordination Points
- **Day 7**: SC1 â†’ SC2 handoff (architecture â†’ implementation)
- **Day 14**: SC2 â†’ SC3 handoff (implementation â†’ integration)
- **Day 19**: All SCs â†’ Hive Queen (final integration)

### Escalation Path
1. Worker â†’ Sub-Coordinator (technical issues)
2. Sub-Coordinator â†’ Hive Queen (coordination issues)
3. Hive Queen â†’ User (strategic decisions)

---

## Next Steps

1. **Hive Queen**: Review and approve coordination plan
2. **Spawn Sub-Coordinators**: Deploy SC1, SC2, SC3 with worker teams
3. **Begin Execution**: SC1 starts architecture validation
4. **Monitor Progress**: Daily status updates from all sub-coordinators
5. **Integrate Deliverables**: Hive Queen merges all outputs
6. **Final Validation**: Run full test suite and quality gates
7. **Release**: Create git commit and update version to v0.6.0

---

## Coordination Completion Criteria

**Phase 1 Complete**: All agents deployed and initial tasks assigned
**Phase 2 Complete**: All deliverables submitted to Hive Queen
**Phase 3 Complete**: Integrated system passes all quality gates
**Mission Success**: v0.6.0 released with all features working

---

Generated by Hive Queen Coordinator
Date: 2025-10-16
Mission: clnrm v0.6.0 Tera Templating Implementation
