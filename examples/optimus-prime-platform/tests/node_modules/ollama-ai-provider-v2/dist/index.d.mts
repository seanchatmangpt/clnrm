import { ProviderV2, LanguageModelV2, EmbeddingModelV2 } from '@ai-sdk/provider';
import { FetchFunction } from '@ai-sdk/provider-utils';
import { z } from 'zod/v4';

type OllamaChatModelId = "athene-v2" | "athene-v2:72b" | "aya-expanse" | "aya-expanse:8b" | "aya-expanse:32b" | "codegemma" | "codegemma:2b" | "codegemma:7b" | "codellama" | "codellama:7b" | "codellama:13b" | "codellama:34b" | "codellama:70b" | "codellama:code" | "codellama:python" | "command-r" | "command-r:35b" | "command-r-plus" | "command-r-plus:104b" | "command-r7b" | "command-r7b:7b" | "deepseek-r1" | "deepseek-r1:1.5b" | "deepseek-r1:7b" | "deepseek-r1:8b" | "deepseek-r1:14b" | "deepseek-r1:32b" | "deepseek-r1:70b" | "deepseek-r1:671b" | "deepseek-coder-v2" | "deepseek-coder-v2:16b" | "deepseek-coder-v2:236b" | "deepseek-v3" | "deepseek-v3:671b" | "devstral" | "devstral:24b" | "dolphin3" | "dolphin3:8b" | "exaone3.5" | "exaone3.5:2.4b" | "exaone3.5:7.8b" | "exaone3.5:32b" | "falcon2" | "falcon2:11b" | "falcon3" | "falcon3:1b" | "falcon3:3b" | "falcon3:7b" | "falcon3:10b" | "firefunction-v2" | "firefunction-v2:70b" | "gemma" | "gemma:2b" | "gemma:7b" | "gemma2" | "gemma2:2b" | "gemma2:9b" | "gemma2:27b" | "gemma3" | "gemma3:1b" | "gemma3:4b" | "gemma3:12b" | "gemma3:27b" | "granite3-dense" | "granite3-dense:2b" | "granite3-dense:8b" | "granite3-guardian" | "granite3-guardian:2b" | "granite3-guardian:8b" | "granite3-moe" | "granite3-moe:1b" | "granite3-moe:3b" | "granite3.1-dense" | "granite3.1-dense:2b" | "granite3.1-dense:8b" | "granite3.1-moe" | "granite3.1-moe:1b" | "granite3.1-moe:3b" | "llama2" | "llama2:7b" | "llama2:13b" | "llama2:70b" | "llama3" | "llama3:8b" | "llama3:70b" | "llama3-chatqa" | "llama3-chatqa:8b" | "llama3-chatqa:70b" | "llama3-gradient" | "llama3-gradient:8b" | "llama3-gradient:70b" | "llama3.1" | "llama3.1:8b" | "llama3.1:70b" | "llama3.1:405b" | "llama3.2" | "llama3.2:1b" | "llama3.2:3b" | "llama3.2-vision" | "llama3.2-vision:11b" | "llama3.2-vision:90b" | "llama3.3" | "llama3.3:70b" | "llama4" | "llama4:16x17b" | "llama4:128x17b" | "llama-guard3" | "llama-guard3:1b" | "llama-guard3:8b" | "llava" | "llava:7b" | "llava:13b" | "llava:34b" | "llava-llama3" | "llava-llama3:8b" | "llava-phi3" | "llava-phi3:3.8b" | "marco-o1" | "marco-o1:7b" | "mistral" | "mistral:7b" | "mistral-large" | "mistral-large:123b" | "mistral-nemo" | "mistral-nemo:12b" | "mistral-small" | "mistral-small:22b" | "mixtral" | "mixtral:8x7b" | "mixtral:8x22b" | "moondream" | "moondream:1.8b" | "openhermes" | "openhermes:v2.5" | "nemotron" | "nemotron:70b" | "nemotron-mini" | "nemotron-mini:4b" | "olmo" | "olmo:7b" | "olmo:13b" | "opencoder" | "opencoder:1.5b" | "opencoder:8b" | "phi3" | "phi3:3.8b" | "phi3:14b" | "phi3.5" | "phi3.5:3.8b" | "phi4" | "phi4:14b" | "qwen" | "qwen:7b" | "qwen:14b" | "qwen:32b" | "qwen:72b" | "qwen:110b" | "qwen2" | "qwen2:0.5b" | "qwen2:1.5b" | "qwen2:7b" | "qwen2:72b" | "qwen2.5" | "qwen2.5:0.5b" | "qwen2.5:1.5b" | "qwen2.5:3b" | "qwen2.5:7b" | "qwen2.5:14b" | "qwen2.5:32b" | "qwen2.5:72b" | "qwen2.5-coder" | "qwen2.5-coder:0.5b" | "qwen2.5-coder:1.5b" | "qwen2.5-coder:3b" | "qwen2.5-coder:7b" | "qwen2.5-coder:14b" | "qwen2.5-coder:32b" | "qwen3" | "qwen3:0.6b" | "qwen3:1.7b" | "qwen3:4b" | "qwen3:8b" | "qwen3:14b" | "qwen3:30b" | "qwen3:32b" | "qwen3:235b" | "qwq" | "qwq:32b" | "sailor2" | "sailor2:1b" | "sailor2:8b" | "sailor2:20b" | "shieldgemma" | "shieldgemma:2b" | "shieldgemma:9b" | "shieldgemma:27b" | "smallthinker" | "smallthinker:3b" | "smollm" | "smollm:135m" | "smollm:360m" | "smollm:1.7b" | "tinyllama" | "tinyllama:1.1b" | "tulu3" | "tulu3:8b" | "tulu3:70b" | (string & {});
declare const ollamaProviderOptions: z.ZodObject<{
    think: z.ZodOptional<z.ZodBoolean>;
    options: z.ZodOptional<z.ZodObject<{
        num_ctx: z.ZodOptional<z.ZodNumber>;
        repeat_last_n: z.ZodOptional<z.ZodNumber>;
        repeat_penalty: z.ZodOptional<z.ZodNumber>;
        temperature: z.ZodOptional<z.ZodNumber>;
        seed: z.ZodOptional<z.ZodNumber>;
        stop: z.ZodOptional<z.ZodArray<z.ZodString>>;
        num_predict: z.ZodOptional<z.ZodNumber>;
        top_k: z.ZodOptional<z.ZodNumber>;
        top_p: z.ZodOptional<z.ZodNumber>;
        min_p: z.ZodOptional<z.ZodNumber>;
    }, z.core.$strip>>;
}, z.core.$strip>;
type OllamaProviderOptions = z.infer<typeof ollamaProviderOptions>;

type OllamaCompletionModelId = (string & {});
interface OllamaCompletionSettings {
    /**
     * Enable or disable the model's thinking process. When enabled, the output will separate
     * the model's thinking from the model's output. When disabled, the model will not think
     * and directly output the content.
     *
     * Only supported by certain models like DeepSeek R1 and Qwen 3.
     */
    think?: boolean;
    /**
     * Echo back the prompt in addition to the completion.
     */
    echo?: boolean;
    /**
     * The suffix that comes after a completion of inserted text.
     */
    suffix?: string;
    /**
     * A unique identifier representing your end-user, which can help Ollama to
     * monitor and detect abuse.
     */
    user?: string;
}

type OllamaEmbeddingModelId = 'text-embedding-3-small' | 'text-embedding-3-large' | 'text-embedding-ada-002' | (string & {});
interface OllamaEmbeddingSettings {
    /**
  Override the maximum number of embeddings per call.
     */
    maxEmbeddingsPerCall?: number;
    /**
  Override the parallelism of embedding calls.
      */
    supportsParallelCalls?: boolean;
    /**
  The number of dimensions the resulting output embeddings should have.
  Only supported in text-embedding-3 and later models.
     */
    dimensions?: number;
    /**
  A unique identifier representing your end-user, which can help Ollama to
  monitor and detect abuse. Learn more.
  */
    user?: string;
}

interface OllamaProvider extends ProviderV2 {
    (modelId: OllamaChatModelId): LanguageModelV2;
    /**
  Creates an Ollama model for text generation.
     */
    languageModel(modelId: OllamaChatModelId): LanguageModelV2;
    /**
  Creates an Ollama chat model for text generation.
     */
    chat(modelId: OllamaChatModelId, settings?: OllamaProviderOptions): LanguageModelV2;
    /**
  Creates an Ollama completion model for text generation.
     */
    completion(modelId: OllamaCompletionModelId, settings?: OllamaCompletionSettings): LanguageModelV2;
    /**
  Creates a model for text embeddings.
     */
    embedding(modelId: OllamaEmbeddingModelId, settings?: OllamaEmbeddingSettings): EmbeddingModelV2<string>;
    /**
  Creates a model for text embeddings.
  
  @deprecated Use `textEmbeddingModel` instead.
     */
    textEmbedding(modelId: OllamaEmbeddingModelId, settings?: OllamaEmbeddingSettings): EmbeddingModelV2<string>;
    /**
  Creates a model for text embeddings.
     */
    textEmbeddingModel(modelId: OllamaEmbeddingModelId, settings?: OllamaEmbeddingSettings): EmbeddingModelV2<string>;
}
interface OllamaProviderSettings {
    /**
  Base URL for the Ollama API calls.
       */
    baseURL?: string;
    /**
  Ollama Organization.
       */
    organization?: string;
    /**
  Ollama project.
       */
    project?: string;
    /**
  Custom headers to include in the requests.
       */
    headers?: Record<string, string>;
    /**
  Ollama compatibility mode. Should be set to `strict` when using the Ollama API,
  and `compatible` when using 3rd party providers. In `compatible` mode, newer
  information such as streamOptions are not being sent. Defaults to 'compatible'.
     */
    compatibility?: 'strict' | 'compatible';
    /**
  Provider name. Overrides the `ollama` default name for 3rd party providers.
     */
    name?: string;
    /**
  Custom fetch implementation. You can use it as a middleware to intercept requests,
  or to provide a custom fetch implementation for e.g. testing.
      */
    fetch?: FetchFunction;
}
/**
Create an Ollama provider instance.
 */
declare function createOllama(options?: OllamaProviderSettings): OllamaProvider;
/**
Default Ollama provider instance.
 */
declare const ollama: OllamaProvider;

declare const ollamaEmbeddingProviderOptions: z.ZodObject<{
    dimensions: z.ZodOptional<z.ZodNumber>;
    truncate: z.ZodOptional<z.ZodBoolean>;
    keepAlive: z.ZodOptional<z.ZodString>;
}, z.core.$strip>;
type OllamaEmbeddingProviderOptions = z.infer<typeof ollamaEmbeddingProviderOptions>;

declare const ollamaCompletionProviderOptions: z.ZodObject<{
    think: z.ZodOptional<z.ZodBoolean>;
    user: z.ZodOptional<z.ZodString>;
    suffix: z.ZodOptional<z.ZodString>;
    echo: z.ZodOptional<z.ZodBoolean>;
}, z.core.$strip>;
type OllamaCompletionProviderOptions = z.infer<typeof ollamaCompletionProviderOptions>;

export { type OllamaCompletionProviderOptions, type OllamaEmbeddingProviderOptions, type OllamaProvider, type OllamaProviderSettings, createOllama, ollama };
