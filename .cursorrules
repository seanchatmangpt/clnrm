# Core Team Best Practices for Cleanroom Testing Framework

## ðŸŽ¯ Error Handling Best Practices

### âŒ NEVER use unwrap() or expect() in production code
```rust
// âŒ Bad: Using unwrap() - can cause panics
let result = some_operation().unwrap();

// âŒ Bad: Using expect() - can cause panics  
let result = some_operation().expect("This should not fail");

// âŒ Bad: Even in Default implementations
impl Default for MyStruct {
    fn default() -> Self {
        Self {
            backend: SomeOperation::new().unwrap(), // NEVER DO THIS!
        }
    }
}

// âœ… Good: Proper error handling
let result = some_operation()?;

// âœ… Good: Proper error handling with context
let result = some_operation().map_err(|e| {
    CleanroomError::internal_error(format!("Operation failed: {}", e))
})?;

// âœ… Good: Default implementations with proper error handling
impl Default for MyStruct {
    fn default() -> Self {
        Self {
            backend: SomeOperation::new()
                .unwrap_or_else(|_| panic!("Failed to create default backend")),
        }
    }
}
```

### âœ… Use structured error types with context
```rust
// âœ… Good: Using CleanroomError with context
fn my_function() -> Result<MyType, CleanroomError> {
    some_operation().map_err(|e| {
        CleanroomError::container_error("Failed to start container")
            .with_context("Container startup failed during initialization")
            .with_source(e.to_string())
    })?;
}
```

## ðŸ”„ Async/Sync Best Practices

### âŒ NEVER make trait methods async - breaks dyn compatibility
```rust
// âŒ Bad: Async trait methods break dyn compatibility
pub trait ServicePlugin: Send + Sync {
    async fn start(&self) -> Result<ServiceHandle>; // BREAKS dyn ServicePlugin!
    async fn stop(&self, handle: ServiceHandle) -> Result<()>; // BREAKS dyn ServicePlugin!
}

// âœ… Good: Keep trait methods sync, use async in implementations
pub trait ServicePlugin: Send + Sync {
    fn start(&self) -> Result<ServiceHandle>; // dyn compatible
    fn stop(&self, handle: ServiceHandle) -> Result<()>; // dyn compatible
}

// Implementation can still be async internally
impl ServicePlugin for MyPlugin {
    fn start(&self) -> Result<ServiceHandle> {
        // Use tokio::task::block_in_place for async operations
        tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(async {
                // Async operations here
                Ok(ServiceHandle::new())
            })
        })
    }
}
```

### âœ… Use async for I/O and long-running operations
```rust
// âœ… Good: Async for file operations, network, containers
pub async fn start_container() -> Result<ContainerHandle, CleanroomError> {
    // Container operations are async
}

pub async fn run_tests() -> Result<TestResults, CleanroomError> {
    // Test execution is async
}

// âŒ Bad: Blocking operations in async context
pub async fn process_data() -> Result<(), CleanroomError> {
    std::thread::sleep(std::time::Duration::from_secs(1)); // Blocking!
    Ok(())
}

// âœ… Good: Use async alternatives
pub async fn process_data() -> Result<(), CleanroomError> {
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await; // Non-blocking
    Ok(())
}
```

### âœ… Use sync for pure computation and simple operations
```rust
// âœ… Good: Sync for simple calculations and data transformations
pub fn calculate_hash(data: &[u8]) -> String {
    // Pure computation - no I/O
    use sha2::{Sha256, Digest};
    let mut hasher = Sha256::new();
    hasher.update(data);
    format!("{:x}", hasher.finalize())
}

pub fn validate_config(config: &Config) -> Result<(), CleanroomError> {
    // Simple validation - no I/O
    if config.timeout > MAX_TIMEOUT {
        return Err(CleanroomError::validation_error("Timeout too large"));
    }
    Ok(())
}
```

## ðŸ§ª Testing Best Practices

### âœ… Use proper async test functions
```rust
// âœ… Good: Async test functions for integration tests
#[tokio::test]
async fn test_container_lifecycle() -> Result<(), CleanroomError> {
    let environment = TestEnvironments::unit_test().await?;
    let container = environment.create_container("test").await?;

    assert!(container.is_running());
    Ok(())
}

// âŒ Bad: Sync test for async operations
#[test]
fn test_container_lifecycle() {
    // This won't work for async operations
    let runtime = tokio::runtime::Runtime::new().unwrap();
    runtime.block_on(async {
        // Test code
    });
}
```

### âœ… Follow AAA pattern (Arrange, Act, Assert)
```rust
// âœ… Good: Clear AAA structure
#[tokio::test]
async fn test_user_authentication_succeeds() -> Result<(), CleanroomError> {
    // Arrange - Set up test data and dependencies
    let environment = TestEnvironments::integration_test().await?;
    let user_credentials = TestData::valid_user_credentials();

    // Act - Execute the code under test
    let result = environment.authenticate_user(&user_credentials).await?;

    // Assert - Verify the results
    assert!(result.success);
    assert!(!result.token.is_empty());
    assert_eq!(result.user_id, expected_user_id);

    Ok(())
}
```

### âœ… Use descriptive test names
```rust
// âœ… Good: Descriptive test names that explain what is being tested
#[tokio::test]
async fn test_container_creation_with_valid_image_succeeds() -> Result<(), CleanroomError> {}

#[tokio::test]
async fn test_container_creation_with_invalid_image_fails_with_proper_error() -> Result<(), CleanroomError> {}

#[tokio::test]
async fn test_concurrent_scenario_execution_maintains_deterministic_order() -> Result<(), CleanroomError> {}

// âŒ Bad: Vague or unclear test names
#[test]
fn test_container() {}

#[test]
fn test_scenario() {}
```

## ðŸ“¦ Module Organization Best Practices

### âœ… Use proper module structure
```rust
// âœ… Good: Clear module organization
pub mod backend {
    pub mod testcontainer;
    pub mod capabilities;
    pub use testcontainer::TestcontainerBackend;
}

pub mod error {
    // Comprehensive error types
}

pub mod scenario {
    // Scenario DSL implementation
}
```

### âœ… Use proper imports and avoid wildcard imports in production code
```rust
// âœ… Good: Specific imports
use crate::error::{CleanroomError, Result};
use crate::backend::{Backend, TestcontainerBackend};
use crate::policy::Policy;

// âŒ Bad: Wildcard imports in production code
use crate::*;
use crate::error::*;
```

## ðŸš« Code Quality Anti-Patterns

### âŒ Avoid printing/logging in production code
```rust
// âŒ Bad: Printing in production code - fakes the process
fn process_data() -> Result<(), CleanroomError> {
    println!("Processing data..."); // Don't do this!
    Ok(())
}

// âœ… Good: Use proper logging through telemetry
fn process_data() -> Result<(), CleanroomError> {
    tracing::info!("Processing data for user {}", user_id);
    Ok(())
}
```

### âŒ NEVER use unwrap() or expect() anywhere in production code
```rust
// âŒ Bad: Even in tests, avoid unwrap() in production code paths
#[test]
fn test_something() {
    let result = production_function().unwrap(); // Don't do this!
}

// âœ… Good: Use proper error handling even in tests
#[test]
fn test_something() -> Result<(), CleanroomError> {
    let result = production_function()?; // Proper error handling
    assert_eq!(result, expected_value);
    Ok(())
}
```

### âŒ Avoid hardcoded dependencies and magic numbers
```rust
// âŒ Bad: Hardcoded values
const MAX_RETRIES: u32 = 3;
const TIMEOUT_SECONDS: u64 = 30;

// âœ… Good: Configurable constants
const DEFAULT_MAX_RETRIES: u32 = 3;
const DEFAULT_TIMEOUT_SECONDS: u64 = 30;

pub struct Config {
    pub max_retries: u32,
    pub timeout_seconds: u64,
}
```

## ðŸ”’ Security Best Practices

### âœ… Use proper error handling for security-sensitive operations
```rust
// âœ… Good: Proper error handling for authentication
pub async fn authenticate_user(credentials: &Credentials) -> Result<AuthToken, CleanroomError> {
    let user = self.db.find_user(&credentials.username).await
        .map_err(|e| CleanroomError::service_error("Authentication failed"))?; // Don't leak internal errors

    if !verify_password(&credentials.password, &user.password_hash)? {
        return Err(CleanroomError::validation_error("Invalid credentials"));
    }

    let token = generate_auth_token(&user)?;
    Ok(token)
}
```

## ðŸ“Š Performance Best Practices

### âœ… Use efficient data structures and algorithms
```rust
// âœ… Good: Use HashMap for O(1) lookups
use std::collections::HashMap;

pub struct ServiceRegistry {
    services: HashMap<String, ServiceHandle>,
}

// âœ… Good: Use VecDeque for FIFO operations
use std::collections::VecDeque;

pub struct TaskQueue {
    tasks: VecDeque<Task>,
}
```

## ðŸš« Breaking Changes and Compatibility

### âŒ NEVER make breaking changes without migration plan
```rust
// âŒ Bad: Changing trait signatures breaks all implementations
pub trait ServicePlugin: Send + Sync {
    fn start(&self) -> Result<ServiceHandle>; // Original
    // Later changed to:
    async fn start(&self) -> Result<ServiceHandle>; // BREAKS ALL IMPLEMENTATIONS!
}

// âœ… Good: Add new methods, deprecate old ones
pub trait ServicePlugin: Send + Sync {
    fn start(&self) -> Result<ServiceHandle>; // Keep for compatibility
    
    #[deprecated(note = "Use start_async instead")]
    fn start_async(&self) -> impl Future<Output = Result<ServiceHandle>>; // New async version
}
```

### âœ… Always maintain backward compatibility
- Add new methods instead of changing existing ones
- Use deprecation warnings for old methods
- Provide migration guides for breaking changes
- Test all existing implementations still work

## ðŸŽ¯ Core Team Standards Summary

1. **Error Handling**: Never use `.unwrap()` or `.expect()` in production code. Always use proper `Result<T, E>` types with meaningful error messages and context.

2. **Async/Sync**: Use `async` for I/O, network, and long-running operations. Use `sync` for pure computation and simple operations. **NEVER make trait methods async** - breaks dyn compatibility.

3. **Trait Design**: Keep traits `dyn` compatible. Use sync methods in traits, implement async internally if needed.

4. **Breaking Changes**: Never make breaking changes without migration plan. Maintain backward compatibility.

5. **Testing**: Follow AAA pattern, use descriptive names, proper async test functions, and avoid external dependencies in unit tests.

6. **Code Quality**: No printing/logging in production code, proper module organization, avoid wildcard imports, use structured error types.

7. **Security**: Proper error handling that doesn't leak internal implementation details, validate all inputs.

8. **Performance**: Use appropriate data structures, avoid unnecessary allocations, consider algorithmic complexity.

These rules ensure FAANG-level code quality, reliability, and maintainability while following the core team's established patterns and best practices.

## âœ… Definition of Done - Core Team Standards

### Before any code is considered complete, ALL of these must be true:

1. **âœ… Compilation**: Code compiles without errors or warnings
2. **âœ… No unwrap()/expect()**: Zero usage of unwrap() or expect() in production code
3. **âœ… Trait Compatibility**: All traits remain `dyn` compatible (no async trait methods)
4. **âœ… Backward Compatibility**: No breaking changes without migration plan
5. **âœ… All Tests Pass**: Every test in the codebase passes
6. **âœ… No Linting Errors**: Zero linting errors or warnings
7. **âœ… Proper Error Handling**: All functions use Result types with meaningful errors
8. **âœ… Async/Sync Patterns**: Proper use of async for I/O, sync for computation

### Validation Checklist:
- [ ] `cargo test` passes completely
- [ ] `cargo clippy` shows no warnings
- [ ] No `unwrap()` or `expect()` in production code
- [ ] All traits are `dyn` compatible
- [ ] No breaking changes to public APIs
- [ ] All error paths use proper Result types
- [ ] Async operations use proper async/await patterns

### If ANY of these fail, the code is NOT ready for production.
