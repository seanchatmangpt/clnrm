# v0.7.0 Remediation Plan

**Status**: CRITICAL - Build Broken
**Priority**: P0 - Blocking Release
**Estimated Time**: 6-10 hours
**Owner**: Development Swarm

---

## Critical Path: Fix Compilation (ETA: 1-2 hours)

### Task 1.1: Create Cache Trait File ⚠️ CRITICAL

**File**: `/Users/sac/clnrm/crates/clnrm-core/src/cache/cache_trait.rs`
**Priority**: P0 - Blocking
**Time**: 30 minutes
**Dependencies**: None

**Error**:
```
error[E0583]: file not found for module `r#trait`
--> crates/clnrm-core/src/cache/mod.rs:33:1
```

**Fix**:
```rust
//! Cache trait definitions for London School TDD approach

use crate::error::Result;
use std::path::Path;

/// Cache trait for abstracting cache backends
///
/// Follows London School TDD - defines collaboration contract
/// for mockable cache implementations.
pub trait Cache: Send + Sync {
    /// Check if a file's hash has changed
    ///
    /// # Arguments
    /// * `path` - File path to check
    /// * `current_hash` - Current hash of the file
    ///
    /// # Returns
    /// * `Ok(true)` if file changed (hash mismatch or not in cache)
    /// * `Ok(false)` if file unchanged (hash matches)
    fn has_changed(&self, path: &Path, current_hash: &str) -> Result<bool>;

    /// Update cached hash for a file
    ///
    /// # Arguments
    /// * `path` - File path
    /// * `hash` - New hash value
    fn update(&mut self, path: &Path, hash: &str) -> Result<()>;

    /// Clear all cached entries
    fn clear(&mut self) -> Result<()>;

    /// Get cache statistics
    fn stats(&self) -> CacheStats;

    /// Get total number of entries
    fn len(&self) -> usize;

    /// Check if cache is empty
    fn is_empty(&self) -> bool {
        self.len() == 0
    }
}

/// Type alias for boxed cache trait object
pub type BoxedCache = Box<dyn Cache>;

/// Cache statistics for monitoring
#[derive(Debug, Clone, Default)]
pub struct CacheStats {
    /// Total number of cache hits
    pub hits: u64,

    /// Total number of cache misses
    pub misses: u64,

    /// Total number of entries in cache
    pub entries: usize,

    /// Cache hit rate (0.0 to 1.0)
    pub hit_rate: f64,
}

impl CacheStats {
    /// Create new cache stats
    pub fn new(hits: u64, misses: u64, entries: usize) -> Self {
        let total = hits + misses;
        let hit_rate = if total > 0 {
            hits as f64 / total as f64
        } else {
            0.0
        };

        Self {
            hits,
            misses,
            entries,
            hit_rate,
        }
    }

    /// Calculate cache hit rate
    pub fn calculate_hit_rate(&mut self) {
        let total = self.hits + self.misses;
        self.hit_rate = if total > 0 {
            self.hits as f64 / total as f64
        } else {
            0.0
        };
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_cache_stats_new() {
        // Arrange & Act
        let stats = CacheStats::new(80, 20, 100);

        // Assert
        assert_eq!(stats.hits, 80);
        assert_eq!(stats.misses, 20);
        assert_eq!(stats.entries, 100);
        assert_eq!(stats.hit_rate, 0.8);
    }

    #[test]
    fn test_cache_stats_zero_requests() {
        // Arrange & Act
        let stats = CacheStats::new(0, 0, 0);

        // Assert
        assert_eq!(stats.hit_rate, 0.0);
    }

    #[test]
    fn test_cache_stats_calculate_hit_rate() {
        // Arrange
        let mut stats = CacheStats {
            hits: 75,
            misses: 25,
            entries: 50,
            hit_rate: 0.0,
        };

        // Act
        stats.calculate_hit_rate();

        // Assert
        assert_eq!(stats.hit_rate, 0.75);
    }
}
```

**Verification**:
```bash
# After creating file, verify module compiles
cargo check -p clnrm-core
```

**Module declaration in `cache/mod.rs`** - ALREADY UPDATED:
```rust
pub mod cache_trait;  // Changed from r#trait
```

---

### Task 1.2: Fix Formatting Module Duplication ⚠️ CRITICAL

**File**: `/Users/sac/clnrm/crates/clnrm-core/src/formatting/mod.rs`
**Priority**: P0 - Blocking
**Time**: 30 minutes
**Dependencies**: None

**Issue**: Lines 54-338 contain duplicate code from `toml_fmt.rs`

**Current file size**: 339 lines (10,142 bytes)
**Target file size**: ~113 lines after removing duplicates

**Fix**: Remove lines 54-338 (duplicate code)

**Expected final structure**:
```rust
//! Formatting Module for Cleanroom v0.7.0
//!
//! Provides multiple formatting capabilities:
//! 1. TOML formatting - Deterministic TOML file formatting
//! 2. Test output formatting - Multiple formats for test results

// TOML formatting submodule
pub mod toml_fmt;

// Test output formatting submodules
pub mod formatter;
pub mod test_result;
pub mod human;
pub mod json;
pub mod junit;
pub mod tap;

use crate::error::Result;

// Re-export TOML formatting functions for backward compatibility
pub use toml_fmt::{format_toml_content, format_toml_file, needs_formatting, verify_idempotency};

// Re-export test output formatting
pub use formatter::{Formatter, FormatterType};
pub use test_result::{TestResult, TestStatus, TestSuite};
pub use human::HumanFormatter;
pub use json::JsonFormatter;
pub use junit::JunitFormatter;
pub use tap::TapFormatter;

/// Format test results using the specified formatter
///
/// # Arguments
/// * `formatter_type` - Type of formatter to use
/// * `suite` - Test suite containing test results
///
/// # Returns
/// * `Result<String>` - Formatted output string
///
/// # Errors
/// Returns error if formatting fails
pub fn format_test_results(formatter_type: FormatterType, suite: &TestSuite) -> Result<String> {
    let formatter: Box<dyn Formatter> = match formatter_type {
        FormatterType::Human => Box::new(HumanFormatter::new()),
        FormatterType::Json => Box::new(JsonFormatter::new()),
        FormatterType::Junit => Box::new(JunitFormatter::new()),
        FormatterType::Tap => Box::new(TapFormatter::new()),
    };

    formatter.format(suite)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_format_test_results_human() -> Result<()> {
        // Arrange
        let suite = TestSuite::new("test_suite");

        // Act
        let result = format_test_results(FormatterType::Human, &suite)?;

        // Assert
        assert!(!result.is_empty());

        Ok(())
    }

    #[test]
    fn test_format_test_results_json() -> Result<()> {
        // Arrange
        let suite = TestSuite::new("test_suite");

        // Act
        let result = format_test_results(FormatterType::Json, &suite)?;

        // Assert
        assert!(!result.is_empty());

        Ok(())
    }

    #[test]
    fn test_format_test_results_junit() -> Result<()> {
        // Arrange
        let suite = TestSuite::new("test_suite");

        // Act
        let result = format_test_results(FormatterType::Junit, &suite)?;

        // Assert
        assert!(!result.is_empty());

        Ok(())
    }

    #[test]
    fn test_format_test_results_tap() -> Result<()> {
        // Arrange
        let suite = TestSuite::new("test_suite");

        // Act
        let result = format_test_results(FormatterType::Tap, &suite)?;

        // Assert
        assert!(!result.is_empty());

        Ok(())
    }
}
```

**Verification**:
```bash
# After editing, verify module compiles
cargo check -p clnrm-core
# Verify tests still pass
cargo test -p clnrm-core --lib formatting
```

---

### Task 1.3: Fix Watch Module Warnings ⚠️ MODERATE

**File**: `/Users/sac/clnrm/crates/clnrm-core/src/watch/mod.rs`
**Priority**: P1 - Warning cleanup
**Time**: 15 minutes
**Dependencies**: None

**Warnings**:
```
warning: unused import: `crate::cli::types::CliConfig`
warning: unused import: `CleanroomError`
```

**Fix**: Remove unused imports on lines 51-52

**Before**:
```rust
use crate::cli::types::CliConfig;
use crate::error::{CleanroomError, Result};
```

**After**:
```rust
use crate::error::Result;
```

**Verification**:
```bash
cargo clippy -p clnrm-core -- -W unused-imports
```

---

### Task 1.4: Verify Complete Compilation ✅ VERIFICATION

**Priority**: P0 - Gate check
**Time**: 15 minutes
**Dependencies**: Tasks 1.1, 1.2, 1.3

**Commands**:
```bash
# Clean build
cargo clean

# Full release build
cargo build --release 2>&1 | tee build.log

# Check for warnings
cargo clippy -- -D warnings 2>&1 | tee clippy.log

# Verify formatting
cargo fmt -- --check
```

**Success Criteria**:
- ✅ Zero compilation errors
- ✅ Zero warnings
- ✅ All crates build successfully

---

## Phase 2: Code Standards Compliance (ETA: 4-6 hours)

### Task 2.1: Remove `.unwrap()` and `.expect()` Usage ⚠️ HIGH PRIORITY

**Priority**: P1 - Code standards
**Time**: 3-4 hours
**Files Affected**: 19 files

**Strategy**: Replace with proper error handling

#### Pattern 1: `.unwrap()` on Option

**❌ BEFORE**:
```rust
let value = some_option.unwrap();
```

**✅ AFTER**:
```rust
let value = some_option.ok_or_else(|| {
    CleanroomError::internal_error("Expected value to be Some, but was None")
})?;
```

#### Pattern 2: `.unwrap()` on Result

**❌ BEFORE**:
```rust
let result = operation().unwrap();
```

**✅ AFTER**:
```rust
let result = operation().map_err(|e| {
    CleanroomError::internal_error(format!("Operation failed: {}", e))
})?;
```

#### Pattern 3: `.expect()` with message

**❌ BEFORE**:
```rust
let value = operation().expect("Operation must succeed");
```

**✅ AFTER**:
```rust
let value = operation().map_err(|e| {
    CleanroomError::internal_error(format!("Operation must succeed: {}", e))
})?;
```

#### Files to Fix (Priority Order)

1. **Production Code** (P0 - High risk of panics):
   - `src/cache/file_cache.rs`
   - `src/cache/memory_cache.rs`
   - `src/validation/shape.rs`
   - `src/validation/otel.rs`
   - `src/validation/span_validator.rs`
   - `src/validation/orchestrator.rs`
   - `src/validation/count_validator.rs`
   - `src/template/mod.rs`
   - `src/template/functions.rs`
   - `src/template/determinism.rs`
   - `src/template/context.rs`
   - `src/services/otel_collector.rs`
   - `src/backend/testcontainer.rs`

2. **CLI Code** (P1 - Acceptable in some cases):
   - `src/cli/utils.rs`
   - `src/cli/commands/v0_7_0/fmt.rs`

3. **Formatting Code** (P1 - May need unwrap for tests):
   - `src/formatting/mod.rs`
   - `src/formatting/toml_fmt.rs`
   - `src/formatting/json.rs`

4. **Watch Code** (P2 - Low risk):
   - `src/watch/debouncer.rs`

**Verification**:
```bash
# Check for remaining unwrap/expect
grep -r "\.unwrap()\|\.expect(" crates/clnrm-core/src/ --exclude-dir=tests

# Should return nothing outside #[cfg(test)] blocks
```

---

### Task 2.2: Review `println!` Usage ⚠️ MEDIUM PRIORITY

**Priority**: P2 - Code standards
**Time**: 1-2 hours
**Files Affected**: 19 files

**Strategy**: Categorize and fix based on context

#### Category 1: Debug Output (Replace with tracing)

**❌ BEFORE**:
```rust
println!("Processing file: {}", path);
```

**✅ AFTER**:
```rust
tracing::debug!("Processing file: {}", path);
```

#### Category 2: User-Facing CLI Output (Keep)

**✅ ACCEPTABLE**:
```rust
// In CLI commands, println! is OK for user output
println!("✅ Tests passed: {}/{}", passed, total);
```

#### Category 3: Error Messages (Use tracing::error!)

**❌ BEFORE**:
```rust
println!("Error: {}", error);
```

**✅ AFTER**:
```rust
tracing::error!("Operation failed: {}", error);
```

#### Files to Review (by Category)

**CLI Commands (Keep most println! for user output)**:
- `src/cli/mod.rs`
- `src/cli/commands/run.rs`
- `src/cli/commands/init.rs`
- `src/cli/commands/services.rs`
- `src/cli/commands/plugins.rs`
- `src/cli/commands/health.rs`
- `src/cli/commands/validate.rs`
- `src/cli/commands/report.rs`
- `src/cli/commands/v0_7_0/diff.rs`
- `src/cli/commands/v0_7_0/lint.rs`
- `src/cli/commands/v0_7_0/dry_run.rs`
- `src/cli/commands/v0_7_0/fmt.rs`

**Production Code (Replace with tracing)**:
- `src/cleanroom.rs`
- `src/macros.rs`
- `src/services/chaos_engine.rs`
- `src/policy.rs`
- `src/marketplace/commands.rs`
- `src/backend/capabilities.rs`
- `src/scenario.rs`

**Verification**:
```bash
# Find println! in production code (excluding CLI)
grep -r "println!" crates/clnrm-core/src/ \
  --exclude-dir=cli \
  --exclude-dir=tests \
  | grep -v "^Binary"
```

---

## Phase 3: Quality Validation (ETA: 1-2 hours)

### Task 3.1: Run Complete Test Suite ✅ VERIFICATION

**Priority**: P0 - Quality gate
**Time**: 30 minutes
**Dependencies**: Phase 1, Phase 2

**Commands**:
```bash
# Run all tests with all features
cargo test --all-features 2>&1 | tee test-output.log

# Run doc tests
cargo test --doc 2>&1 | tee doc-test-output.log

# Count test results
echo "Test Summary:"
grep -E "test result:|passed" test-output.log | tail -5
```

**Success Criteria**:
- ✅ All tests pass
- ✅ No test failures or panics
- ✅ Doc tests pass

---

### Task 3.2: Measure Code Coverage ✅ VERIFICATION

**Priority**: P1 - Quality metric
**Time**: 30 minutes
**Dependencies**: Task 3.1

**Commands**:
```bash
# Install tarpaulin if not installed
cargo install cargo-tarpaulin

# Run coverage with HTML output
cargo tarpaulin \
  --all-features \
  --out Html \
  --output-dir coverage/ \
  --exclude-files "tests/*" \
  --timeout 300 \
  2>&1 | tee coverage.log

# Display coverage summary
echo "Coverage Summary:"
grep "Coverage" coverage.log
```

**Success Criteria**:
- ✅ Overall coverage ≥ 80%
- ✅ Cache subsystem ≥ 90%
- ✅ Watch subsystem ≥ 90%
- ✅ Formatting subsystem ≥ 85%
- ✅ Shape validation ≥ 90%

**Coverage Report Location**: `coverage/index.html`

---

### Task 3.3: Run Performance Benchmarks ✅ VERIFICATION

**Priority**: P2 - Performance validation
**Time**: 30 minutes
**Dependencies**: Phase 1

**Commands**:
```bash
# Run DX features benchmarks
cargo bench --bench dx_features_benchmarks 2>&1 | tee bench-output.log

# Extract key metrics
echo "Benchmark Summary:"
grep -E "time:|ns/iter" bench-output.log | tail -20
```

**Success Criteria**:
- ✅ Cache lookup < 1ms
- ✅ Watch debouncing < 50ms
- ✅ TOML formatting < 10ms for small files
- ✅ Shape validation < 5ms per schema

**Benchmark Report Location**: `target/criterion/`

---

### Task 3.4: Final Quality Gate Check ✅ VERIFICATION

**Priority**: P0 - Release gate
**Time**: 15 minutes
**Dependencies**: All previous tasks

**Checklist**:
```bash
# 1. Clean build
cargo clean && cargo build --release

# 2. All tests pass
cargo test --all-features

# 3. Zero clippy warnings
cargo clippy --all-features -- -D warnings

# 4. Code formatted correctly
cargo fmt -- --check

# 5. No unwrap/expect in production
grep -r "\.unwrap()\|\.expect(" crates/clnrm-core/src/ \
  --exclude-dir=tests \
  | grep -v "^Binary" \
  | wc -l
# Should output: 0

# 6. Framework self-test
cargo run -- self-test
```

**Success Criteria**: ALL commands succeed

---

## Progress Tracking

### Phase 1: Compilation (CRITICAL)

- [ ] Task 1.1: Create cache trait file (30 min)
- [ ] Task 1.2: Fix formatting duplication (30 min)
- [ ] Task 1.3: Fix watch warnings (15 min)
- [ ] Task 1.4: Verify compilation (15 min)

**Phase 1 ETA**: 1.5 hours

### Phase 2: Code Standards (HIGH PRIORITY)

- [ ] Task 2.1: Remove unwrap/expect (3-4 hours)
  - [ ] Production code (2-3 hours)
  - [ ] CLI code (30 min)
  - [ ] Formatting code (30 min)
  - [ ] Watch code (15 min)
- [ ] Task 2.2: Review println! usage (1-2 hours)
  - [ ] Production code (1 hour)
  - [ ] CLI code review (30 min)

**Phase 2 ETA**: 4-6 hours

### Phase 3: Validation (VERIFICATION)

- [ ] Task 3.1: Run test suite (30 min)
- [ ] Task 3.2: Measure coverage (30 min)
- [ ] Task 3.3: Run benchmarks (30 min)
- [ ] Task 3.4: Final quality gate (15 min)

**Phase 3 ETA**: 1.75 hours

---

## Risk Assessment

### Critical Risks

1. **Build Broken** - CURRENT
   - Impact: CRITICAL
   - Probability: 100% (current state)
   - Mitigation: Phase 1 fixes

2. **Production Panics from `.unwrap()`**
   - Impact: HIGH
   - Probability: 60%
   - Mitigation: Task 2.1

3. **Test Failures After Fixes**
   - Impact: MEDIUM
   - Probability: 30%
   - Mitigation: Comprehensive testing in Phase 3

### Moderate Risks

4. **Coverage Below Target**
   - Impact: MEDIUM
   - Probability: 20%
   - Mitigation: Add tests if needed

5. **Performance Regressions**
   - Impact: MEDIUM
   - Probability: 15%
   - Mitigation: Benchmarks in Task 3.3

---

## Success Metrics

### Must-Have (Release Blockers)

- ✅ Zero compilation errors
- ✅ Zero compilation warnings
- ✅ All tests pass
- ✅ Zero clippy warnings
- ✅ Framework self-test passes

### Should-Have (Quality Targets)

- ✅ Test coverage ≥ 90%
- ✅ Zero `.unwrap()/.expect()` in production code
- ✅ Proper `tracing` usage instead of `println!`
- ✅ Performance benchmarks meet targets

### Nice-to-Have (Stretch Goals)

- ✅ Documentation examples all work
- ✅ Integration tests cover all workflows
- ✅ Property tests validate edge cases

---

## Escalation Path

### If Phase 1 Takes > 2 Hours

1. Notify Hive Queen
2. Request additional Coder Agent support
3. Parallelize tasks if possible

### If Phase 2 Takes > 6 Hours

1. Re-prioritize: Focus on production code first
2. Defer CLI code review to post-release
3. Add tech debt tickets for remaining issues

### If Tests Fail in Phase 3

1. Identify failing subsystems
2. Roll back problematic changes
3. Fix and re-test iteratively
4. Escalate to Hive Queen if > 3 iterations needed

---

## Communication Plan

### Status Updates

- **Hourly updates** during Phase 1 (critical path)
- **After each task** completion in Phase 2
- **Immediate notification** of any blocking issues

### Reporting Format

```
Status Update - v0.7.0 Remediation

Phase: [1/2/3]
Task: [Current task]
Progress: [X/Y tasks complete]
ETA: [Remaining time]
Blockers: [Any issues]
Next Steps: [Next task]
```

### Final Sign-Off

Upon completion:
1. Run final QA validation
2. Generate release report
3. Submit to Hive Queen for approval
4. Update project documentation

---

## Next Steps

**IMMEDIATE**: Begin Phase 1, Task 1.1
**PRIORITY**: Complete Phase 1 within 2 hours
**TARGET**: Full remediation complete within 10 hours

---

**Document Owner**: Production Validation Agent (QA Lead)
**Last Updated**: 2025-10-17
**Status**: ACTIVE - Awaiting execution
